{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "# %pip install PyQt5 pyqtgraph\n",
    "\n",
    "import time\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sympy as sym\n",
    "\n",
    "from typing import Iterable\n",
    "import pyqtgraph as pg\n",
    "from pyqtgraph.Qt import QtCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animation:\n",
    "    def __init__(self, landmarks: Iterable[float]) -> None:\n",
    "        # window\n",
    "        self.win = pg.plot(show=True)\n",
    "        self.win.resize(800, 600)\n",
    "        self.win.setWindowTitle(\"Animation Ex03\")\n",
    "        self.win.setBackground(\"w\")\n",
    "        self.win.setAspectLocked(lock=True, ratio=1)\n",
    "        self.win.getViewBox().wheelEvent = lambda event: None\n",
    "        self.win.setXRange(-2, 10)\n",
    "        self.win.setYRange(-3, 4)\n",
    "\n",
    "        # colors\n",
    "        color_landmarks = pg.mkColor(10, 10, 10)  # black\n",
    "        color_landmarks.setAlpha(255)\n",
    "\n",
    "        color_pos_true = pg.mkColor(0, 114, 189)  # blue\n",
    "        color_pos_true.setAlpha(220)\n",
    "\n",
    "        color_pos_est = pg.mkColor(252, 41, 30)  # red\n",
    "        color_pos_est.setAlpha(220)\n",
    "\n",
    "        color_ellipse = pg.mkColor(252, 41, 30)  # red\n",
    "        color_ellipse.setAlpha(60)\n",
    "\n",
    "        # landmarks\n",
    "        self.landmarks = pg.ScatterPlotItem()\n",
    "        self.landmarks.setPen(color_landmarks)\n",
    "        self.landmarks.setBrush(color_landmarks)\n",
    "        self.landmarks.setData(x=landmarks[:, 0], y=landmarks[:, 1])\n",
    "\n",
    "        # true position\n",
    "        self.pos_true = pg.ScatterPlotItem()\n",
    "        self.pos_true.setSize(5)\n",
    "        self.pos_true.setPen(color_pos_true)\n",
    "        self.pos_true.setBrush(color_pos_true)\n",
    "\n",
    "        # estimated position\n",
    "        self.pos_est = pg.ScatterPlotItem()\n",
    "        self.pos_est.setSize(5)\n",
    "        self.pos_est.setPen(color_pos_est)\n",
    "        self.pos_est.setBrush(color_pos_est)\n",
    "\n",
    "        # uncertainty ellipse\n",
    "        self.ellipse = pg.PlotCurveItem()\n",
    "        self.ellipse.setPen(color_ellipse, width=4)\n",
    "        self.ellipse.setBrush(color_ellipse)\n",
    "        self.ellipse.setFillLevel(0)\n",
    "\n",
    "        # legend\n",
    "        self.legend = pg.LegendItem()\n",
    "        self.legend.setParentItem(self.win.graphicsItem())\n",
    "        self.legend.setOffset((20, 1))\n",
    "        self.legend.addItem(self.landmarks, \"Landmarks\")\n",
    "        self.legend.addItem(self.pos_true, \"True position\")\n",
    "        self.legend.addItem(self.pos_est, \"Estimated position\")\n",
    "        self.legend.addItem(self.ellipse, \"Uncertainty ellipse\")\n",
    "\n",
    "        self.win.addItem(self.landmarks)\n",
    "        self.win.addItem(self.pos_true)\n",
    "        self.win.addItem(self.pos_est)\n",
    "        self.win.addItem(self.ellipse)\n",
    "\n",
    "    def compute_ellipse(\n",
    "        self, mean: Iterable[float], covariance: Iterable[float]\n",
    "    ) -> Iterable[float]:\n",
    "        M = 10\n",
    "\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(covariance)\n",
    "        order = eigenvalues.argsort()[::-1]\n",
    "        eigenvalues, eigenvectors = eigenvalues[order], eigenvectors[:, order]\n",
    "\n",
    "        # Get the index of the largest eigenvector\n",
    "        lamda1 = eigenvalues.max()\n",
    "        lamda2 = eigenvalues.min()\n",
    "        largest_eigenvec_idx = eigenvalues.argmax()\n",
    "        largest_eigenvec = eigenvectors[:, largest_eigenvec_idx]\n",
    "\n",
    "        # Calculate the angle of the ellipse\n",
    "        angle = np.arctan2(largest_eigenvec[1], largest_eigenvec[0])\n",
    "\n",
    "        # Full ellipse around zero\n",
    "        theta = np.linspace(0, 2 * np.pi, 50)\n",
    "        x = M * np.sqrt(lamda1) * np.cos(theta)\n",
    "        y = M * np.sqrt(lamda2) * np.sin(theta)\n",
    "\n",
    "        sin_th = np.sin(angle).item()\n",
    "        cos_th = np.cos(angle).item()\n",
    "        rot_mat = np.array([[cos_th, -sin_th], [sin_th, cos_th]])\n",
    "\n",
    "        ellipse = np.array([x, y])\n",
    "        ellipse = rot_mat @ ellipse\n",
    "\n",
    "        # Shift the ellipse to the mean\n",
    "        ellipse[0] += mean[0]\n",
    "        ellipse[1] += mean[1]\n",
    "\n",
    "        return ellipse\n",
    "\n",
    "    def update(\n",
    "        self, mean: Iterable[float], covariance: Iterable[float], true_position=None\n",
    "    ) -> None:\n",
    "        if true_position is not None:\n",
    "            self.pos_true.setData([true_position[0]], [true_position[1]])\n",
    "\n",
    "        self.pos_est.setData([mean[0]], [mean[1]])\n",
    "\n",
    "        if covariance is not None:\n",
    "            ellipse = self.compute_ellipse(mean, covariance)\n",
    "            self.ellipse.setData(ellipse[0], ellipse[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sensor:\n",
    "    def __init__(self, load_file):\n",
    "        mat = sp.io.loadmat(load_file)\n",
    "\n",
    "        # ground truth\n",
    "        t = mat[\"t\"]\n",
    "        x_true = mat[\"x_true\"]\n",
    "        y_true = mat[\"y_true\"]\n",
    "        th_true = mat[\"th_true\"]\n",
    "        true_valid = mat[\"true_valid\"]\n",
    "        l = mat[\"l\"]\n",
    "        d = mat[\"d\"]\n",
    "\n",
    "        # mesaurements\n",
    "        r = mat[\"r\"]\n",
    "        r_var = mat[\"r_var\"]\n",
    "        b = mat[\"b\"]\n",
    "        b_var = mat[\"b_var\"]\n",
    "        v = mat[\"v\"]\n",
    "        v_var = mat[\"v_var\"]\n",
    "        om = mat[\"om\"]\n",
    "        om_var = mat[\"om_var\"]\n",
    "\n",
    "        self.t = t.reshape(-1)\n",
    "        self.n_samples = len(t)\n",
    "        self.X_true = np.hstack((x_true, y_true, th_true))\n",
    "        self.Y = np.zeros((self.n_samples, l.shape[0], 2))\n",
    "        self.Y[:, :, 0], self.Y[:, :, 1] = r, b\n",
    "        self.u = np.hstack((v, om))\n",
    "        self.params = {\n",
    "            \"l\": l,\n",
    "            \"d\": d.item(),\n",
    "            \"Q\": np.diag([v_var.item(), om_var.item()]),\n",
    "            \"R\": np.diag([r_var.item(), b_var.item()]),\n",
    "        }\n",
    "        self.k = 0\n",
    "\n",
    "    def get_params(self, key):\n",
    "        if key not in self.params:\n",
    "            raise ValueError(f\"key {key} is not in params\")\n",
    "        return self.params[key]\n",
    "\n",
    "    def step(self) -> bool:\n",
    "        if self.k < self.n_samples - 1:\n",
    "            self.k += 1\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "    def get_time(self):\n",
    "        return self.t[self.k]\n",
    "\n",
    "    def get_X_k_true(self):\n",
    "        return self.X_true[self.k]\n",
    "\n",
    "    def get_u_k(self):\n",
    "        return self.u[self.k]\n",
    "\n",
    "    def get_Y_k(self):\n",
    "        return self.Y[self.k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator:\n",
    "    def __init__(self, landmarks, d, dt, X_0, P_0, Q, R, r_max=100):\n",
    "        self.landmarks = landmarks\n",
    "        self.X_hat = X_0\n",
    "        self.P_hat = P_0\n",
    "        self.Q = Q\n",
    "        self.R = R\n",
    "        self.dt = dt\n",
    "        self.d = d\n",
    "        self.r_max = r_max\n",
    "\n",
    "        self.X_check = None\n",
    "        self.P_check = None\n",
    "\n",
    "    def predict(self, u_k, X_true_k_1=None):\n",
    "        # input\n",
    "        v_k = u_k[0]\n",
    "        om_k = u_k[1]\n",
    "\n",
    "        # last state\n",
    "        x_hat = self.X_hat[0]\n",
    "        y_hat = self.X_hat[1]\n",
    "        th_hat = self.X_hat[2]\n",
    "\n",
    "        # operational point\n",
    "        if X_true_k_1 is None:\n",
    "            x_op = x_hat\n",
    "            y_op = y_hat\n",
    "            th_op = th_hat\n",
    "        else:\n",
    "            x_op = X_true_k_1[0]\n",
    "            y_op = X_true_k_1[1]\n",
    "            th_op = X_true_k_1[2]\n",
    "\n",
    "        # compute P_check\n",
    "        ## make H_k_1\n",
    "        H_k_1 = np.matrix(\n",
    "            [\n",
    "                [1, 0, -self.dt * np.sin(th_op) * v_k],\n",
    "                [0, 1, self.dt * np.cos(th_op) * v_k],\n",
    "                [0, 0, 1],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        ## make Q_k_prime\n",
    "        J_h2w = np.matrix(\n",
    "            [[self.dt * np.cos(th_op), 0], [self.dt * np.sin(th_op), 0], [0, self.dt]]\n",
    "        )\n",
    "        Q_k_prime = J_h2w @ self.Q @ J_h2w.T\n",
    "\n",
    "        ## P_check\n",
    "        self.P_check = H_k_1 @ self.P_hat @ H_k_1.T + Q_k_prime\n",
    "\n",
    "        # compute X_check\n",
    "        x_k_check = x_hat + self.dt * np.cos(th_hat) * v_k\n",
    "        y_k_check = y_hat + self.dt * np.sin(th_hat) * v_k\n",
    "        th_k_check = th_hat + self.dt * om_k\n",
    "        self.X_check = np.array([x_k_check, y_k_check, th_k_check])\n",
    "\n",
    "    def valid_landmarks(self, Y_k) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            Y_k: 17 x 2 matrix (r, b) of range and bearing measurements\n",
    "        Returns:\n",
    "            valid landmark index (1d array)\n",
    "        \"\"\"\n",
    "        is_visible = np.all(Y_k != 0, axis=1)\n",
    "        is_under_threshold = Y_k[:, 0] <= self.r_max\n",
    "        valid_idx = np.where(is_visible & is_under_threshold)[0]\n",
    "        return valid_idx\n",
    "\n",
    "    def correct(self, Y_k):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            Y_k: 17 x 2 matrix (r, b) of range and bearing measurements\n",
    "        \"\"\"\n",
    "        # check valid landmarks\n",
    "        valid_idx = self.valid_landmarks(Y_k)\n",
    "        landmarks_valid = self.landmarks[valid_idx]\n",
    "        n_valid = len(valid_idx)\n",
    "\n",
    "        if n_valid == 0:\n",
    "            self.X_hat = self.X_check\n",
    "            self.P_hat = self.P_check\n",
    "            return\n",
    "\n",
    "        # compute K_k\n",
    "        ## compute G_k\n",
    "        x_l_vaild = landmarks_valid[:, 0]\n",
    "        y_l_vaild = landmarks_valid[:, 1]\n",
    "\n",
    "        x_k = self.X_check[0]\n",
    "        y_k = self.X_check[1]\n",
    "        th_k = self.X_check[2]\n",
    "\n",
    "        ### intermediate variable\n",
    "        term1 = x_l_vaild - x_k - self.d * np.cos(th_k)\n",
    "        term2 = y_l_vaild - y_k - self.d * np.sin(th_k)\n",
    "        term3 = term1**2 + term2**2\n",
    "\n",
    "        ### compute G_k in a for loop\n",
    "        G_k = np.zeros((n_valid * 2, 3))\n",
    "        for i in range(n_valid):\n",
    "            G_k[2 * i, 0] = -term1[i] / np.sqrt(term3[i])\n",
    "            G_k[2 * i, 1] = -term2[i] / np.sqrt(term3[i])\n",
    "            G_k[2 * i, 2] = (\n",
    "                -self.d * term2[i] * np.cos(th_k) + self.d * term1[i] * np.sin(th_k)\n",
    "            ) / np.sqrt(term3[i])\n",
    "            G_k[2 * i + 1, 0] = term2[i] / term3[i]\n",
    "            G_k[2 * i + 1, 1] = -term1[i] / term3[i]\n",
    "            G_k[2 * i + 1, 2] = (\n",
    "                -1\n",
    "                + (-self.d * term2[i] * np.sin(th_k) - self.d * term1[i] * np.cos(th_k))\n",
    "                / term3[i]\n",
    "            )\n",
    "\n",
    "        ## compute R_k_prime\n",
    "        R_k_lifted = np.diag(np.tile(np.diag(self.R), n_valid))\n",
    "        R_k_prime = R_k_lifted\n",
    "\n",
    "        ## compute K_k\n",
    "        K_k = (\n",
    "            self.P_check @ G_k.T @ np.linalg.inv(G_k @ self.P_check @ G_k.T + R_k_prime)\n",
    "        )\n",
    "\n",
    "        # compute P_hat\n",
    "        self.P_hat = (np.eye(3) - K_k @ G_k) @ self.P_check\n",
    "\n",
    "        # compute X_hat\n",
    "        ## compute Y_pred of valid landmarks\n",
    "        r_pred_valid = np.sqrt(term3)\n",
    "\n",
    "        ## compute b_pred of valid landmarks\n",
    "        b_pred_valid = np.arctan2(term2, term1) - th_k\n",
    "        b_pred_valid = (\n",
    "            np.mod(b_pred_valid + np.pi, 2 * np.pi) - np.pi\n",
    "        )  # wrap to [-pi, pi]\n",
    "\n",
    "        ## compute Y_pred and innovation of valid landmarks: 2 n_valid x 1\n",
    "        Y_pred_valid = np.vstack((r_pred_valid, b_pred_valid)).T.reshape(-1)\n",
    "        Y_k_valid = Y_k[valid_idx].reshape(-1)\n",
    "        innovation = Y_k_valid - Y_pred_valid\n",
    "\n",
    "        self.X_hat = self.X_check + K_k @ innovation\n",
    "        self.X_hat = np.array(self.X_hat).reshape(-1)\n",
    "\n",
    "    def get_result(self) -> (np.ndarray, np.ndarray):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            X_hat: 3 x 1 array of the current state estimate\n",
    "            P_hat: 3 x 3 array of the current state covariance\n",
    "        \"\"\"\n",
    "        return self.X_hat, self.P_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speed = 100\n",
    "r_max = 1\n",
    "\n",
    "sensor = Sensor(load_file=\"dataset2.mat\")\n",
    "\n",
    "good_X0 = sensor.get_X_k_true()\n",
    "bad_X0 = np.array([1, 1, 0.1])\n",
    "\n",
    "estimator = Estimator(\n",
    "    landmarks=sensor.get_params(\"l\"),\n",
    "    d=sensor.get_params(\"d\"),\n",
    "    dt=0.1,\n",
    "    X_0=good_X0,\n",
    "    P_0=np.diag([1, 1, 0.1]),\n",
    "    Q=sensor.get_params(\"Q\"),\n",
    "    R=sensor.get_params(\"R\"),\n",
    "    r_max=r_max,\n",
    ")\n",
    "\n",
    "animation = Animation(landmarks=sensor.get_params(\"l\"))\n",
    "\n",
    "def update():\n",
    "    global animation, sensor, estimator, timer\n",
    "    if not sensor.step():\n",
    "        timer.stop()\n",
    "        print(\"Finished\")\n",
    "        return\n",
    "    estimator.predict(sensor.get_u_k())\n",
    "    estimator.correct(sensor.get_Y_k())\n",
    "    X_hat, P_hat = estimator.get_result()\n",
    "    animation.update(X_hat[0:2], P_hat[:2, :2], sensor.get_X_k_true()[:2])\n",
    "\n",
    "\n",
    "# plot initial state\n",
    "X_hat, P_hat = estimator.get_result()\n",
    "animation.update(X_hat[0:2], P_hat[:2, :2], sensor.get_X_k_true()[:2])\n",
    "\n",
    "timer = QtCore.QTimer()\n",
    "timer.timeout.connect(update)\n",
    "timer.start(int(1000 * 0.1 / speed))\n",
    "pg.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data\n",
    "# mat = sp.io.loadmat(\"dataset2.mat\")\n",
    "# mat.keys()\n",
    "# # '__header__', '__version__', '__globals__',\n",
    "# # 't', 'r', 'b', 'v', 'om', 'l', 'x_true', 'y_true', 'th_true', 'true_valid',\n",
    "# # 'd', 'r_var', 'b_var', 'v_var', 'om_var'\n",
    "\n",
    "# # ground truth\n",
    "# t = mat[\"t\"]  # 12609 x 1\n",
    "# x_true = mat[\"x_true\"]  # 12609 x 1\n",
    "# y_true = mat[\"y_true\"]  # 12609 x 1\n",
    "# th_true = mat[\"th_true\"]  # 12609 x 1\n",
    "# true_valid = mat[\"true_valid\"]  # 12609 x 1\n",
    "# landmarks = mat[\"l\"]  # 17 x 2 matrix (x,y) of landmark locations\n",
    "# dist = mat[\n",
    "#     \"d\"\n",
    "# ]  # 1 x 1 the distance between the center of the robot and the laser rangeﬁnder\n",
    "\n",
    "# # mesaurements\n",
    "# r = mat[\"r\"]  # 12609 x 17\n",
    "# r_var = mat[\"r_var\"]  # 1 x 1\n",
    "# b = mat[\"b\"]  # 12609 × 17 array containing the bearing\n",
    "# b_var = mat[\"b_var\"]  # 1 x 1\n",
    "# v = mat[\"v\"]  # 12609 × 1 array containing the translational speed\n",
    "# v_var = mat[\"v_var\"]  # 1 x 1\n",
    "# om = mat[\"om\"]  # 12609 × 1 array containing the rotational speed omega\n",
    "# om_var = mat[\"om_var\"]  # 1 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_samples = t.shape[0]\n",
    "# n_landmarks = landmarks.shape[0]\n",
    "\n",
    "# X_true = np.hstack((x_true, y_true, th_true))\n",
    "\n",
    "# u = np.hstack((v, om))\n",
    "\n",
    "# Y_true = np.zeros((n_samples, n_landmarks, 2))\n",
    "# Y_true[:, :, 0] = r\n",
    "# Y_true[:, :, 1] = b\n",
    "\n",
    "# Q = np.diag(\n",
    "#     [\n",
    "#         v_var.item(),\n",
    "#         om_var.item(),\n",
    "#     ]\n",
    "# )\n",
    "# R = np.diag([r_var.item(), b_var.item()])\n",
    "# T = 0.1\n",
    "# d = dist.item()\n",
    "\n",
    "# # initial state\n",
    "# X_0 = X_true[0]\n",
    "# P_0 = np.diag([1, 1, 0.1])\n",
    "\n",
    "# X_hat = X_0\n",
    "# P_hat = P_0\n",
    "\n",
    "# # input\n",
    "\n",
    "# # k = np.random.randint(0, 12609)\n",
    "# # l = np.random.randint(0, 17)\n",
    "\n",
    "# k = 1\n",
    "# r_max = 3  # 5, 3, 1\n",
    "\n",
    "# # check valid landmark\n",
    "# Y_k = Y_true[k]\n",
    "# is_visible = np.all(Y_k != 0, axis=1)\n",
    "# is_under_threshold = Y_k[:, 0] <= r_max\n",
    "# valid_idx = np.where(is_visible & is_under_threshold)[0]\n",
    "\n",
    "# ## sensor reading\n",
    "# u_k = u[k]\n",
    "\n",
    "# v_k = u_k[0]\n",
    "# om_k = u_k[1]\n",
    "\n",
    "# x_hat = X_hat[0]\n",
    "# y_hat = X_hat[1]\n",
    "# th_hat = X_hat[2]\n",
    "\n",
    "# ## landmark\n",
    "# landmarks_valid = landmarks[valid_idx]\n",
    "\n",
    "# # prediction\n",
    "\n",
    "# ## H\n",
    "# H = np.matrix(\n",
    "#     [[1, 0, -T * np.sin(th_hat) * v_k], [0, 1, T * np.cos(th_hat) * v_k], [0, 0, 1]]\n",
    "# )\n",
    "\n",
    "# ## Q_prime\n",
    "# J_h_w = np.matrix([[T * np.cos(th_hat), 0], [T * np.sin(th_hat), 0], [0, T]])\n",
    "# Q_prime = J_h_w @ Q @ J_h_w.T\n",
    "\n",
    "# ## P_check\n",
    "# P_check = H @ P_hat @ H.T + Q_prime\n",
    "\n",
    "# ## X_check\n",
    "# x_k = x_hat + T * np.cos(th_hat) * v_k\n",
    "# y_k = y_hat + T * np.sin(th_hat) * v_k\n",
    "# th_k = th_hat + T * om_k\n",
    "# X_check = np.array([x_k, y_k, th_k])\n",
    "\n",
    "# ## G ((2 * n_valid), 3)\n",
    "# landmarks_valid = landmarks[valid_idx]\n",
    "# n_valid = len(valid_idx)\n",
    "# G = np.zeros((n_valid * 2, 3))\n",
    "\n",
    "# x_l_vaild = landmarks_valid[:, 0]\n",
    "# y_l_vaild = landmarks_valid[:, 1]\n",
    "\n",
    "# term1 = x_l_vaild - x_k - d * np.cos(th_k)\n",
    "# term2 = y_l_vaild - y_k - d * np.sin(th_k)\n",
    "# term3 = term1**2 + term2**2\n",
    "\n",
    "# for i in range(n_valid):\n",
    "#     # x_l = landmarks_valid[i, 0]\n",
    "#     # y_l = landmarks_valid[i, 1]\n",
    "\n",
    "#     # term1 = x_l - x_k - d * np.cos(th_k)\n",
    "#     # term2 = y_l - y_k - d * np.sin(th_k)\n",
    "#     # term3 = term1**2 + term2**2\n",
    "\n",
    "#     G[2 * i, 0] = -term1[i] / np.sqrt(term3[i])\n",
    "#     G[2 * i, 1] = -term2[i] / np.sqrt(term3[i])\n",
    "#     G[2 * i, 2] = (\n",
    "#         -d * term2[i] * np.cos(th_k) + d * term1[i] * np.sin(th_k)\n",
    "#     ) / np.sqrt(term3[i])\n",
    "#     G[2 * i + 1, 0] = term2[i] / term3[i]\n",
    "#     G[2 * i + 1, 1] = -term1[i] / term3[i]\n",
    "#     G[2 * i + 1, 2] = (\n",
    "#         -1 + (-d * term2[i] * np.sin(th_k) - d * term1[i] * np.cos(th_k)) / term3[i]\n",
    "#     )\n",
    "\n",
    "\n",
    "# ## R_prime\n",
    "# R_lifted = np.diag(np.tile(np.diag(R), n_valid))\n",
    "# R_prime = R_lifted\n",
    "\n",
    "# ## K\n",
    "# K = P_check @ G.T @ np.linalg.inv(G @ P_check @ G.T + R_prime)\n",
    "\n",
    "# # correction\n",
    "# ## P_hat\n",
    "# P_hat = (np.eye(3) - K @ G) @ P_check\n",
    "\n",
    "# ## X_hat\n",
    "# r_pred = np.sqrt(term3)\n",
    "\n",
    "# b_pred = np.arctan2(term2, term1) - th_k\n",
    "# b_pred = np.mod(b_pred + np.pi, 2 * np.pi) - np.pi  # wrap to [-pi, pi]\n",
    "\n",
    "# Y_pred = np.vstack((r_pred, b_pred)).T.reshape(-1)\n",
    "# Y_true_k_valid = Y_true[k, valid_idx].reshape(-1)\n",
    "\n",
    "# print(K.shape, Y_true_k_valid.shape, Y_pred.shape)\n",
    "\n",
    "# X_hat = X_check + K @ (Y_true_k_valid - Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(d*cos(theta_k) + x_k - x_l)/sqrt((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2), (d*sin(theta_k) + y_k - y_l)/sqrt((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2), (-d*(-d*sin(theta_k) - y_k + y_l)*cos(theta_k) + d*(-d*cos(theta_k) - x_k + x_l)*sin(theta_k))/sqrt((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2)], [-(d*sin(theta_k) + y_k - y_l)/((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2), -(-d*cos(theta_k) - x_k + x_l)/((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2), d*(d*sin(theta_k) + y_k - y_l)*sin(theta_k)/((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2) - d*(-d*cos(theta_k) - x_k + x_l)*cos(theta_k)/((-d*sin(theta_k) - y_k + y_l)**2 + (-d*cos(theta_k) - x_k + x_l)**2) - 1]]\n"
     ]
    }
   ],
   "source": [
    "# compute G\n",
    "x_k, y_k, theta_k, x_l, y_l, d = sym.symbols(\"x_k y_k theta_k x_l y_l d\")\n",
    "\n",
    "# Define the observation function g(x_k, n_k^l)\n",
    "g_r = sym.sqrt(\n",
    "    (x_l - x_k - d * sym.cos(theta_k)) ** 2 + (y_l - y_k - d * sym.sin(theta_k)) ** 2\n",
    ")\n",
    "g_phi = (\n",
    "    sym.atan2(y_l - y_k - d * sym.sin(theta_k), x_l - x_k - d * sym.cos(theta_k))\n",
    "    - theta_k\n",
    ")\n",
    "\n",
    "# Compute the Jacobian matrix of g with respect to x_k, y_k, theta_k\n",
    "\n",
    "J_g = [\n",
    "    [sym.diff(g_r, x_k), sym.diff(g_r, y_k), sym.diff(g_r, theta_k)],\n",
    "    [sym.diff(g_phi, x_k), sym.diff(g_phi, y_k), sym.diff(g_phi, theta_k)],\n",
    "]\n",
    "\n",
    "print(J_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\left[\\begin{matrix}\\frac{d \\cos{\\left(\\theta_{k} \\right)} + x_{k} - x_{l}}{\\sqrt{\\left(- d \\sin{\\left(\\theta_{k} \\right)} - y_{k} + y_{l}\\right)^{2} + \\left(- d \\cos{\\left(\\theta_{k} \\right)} - x_{k} + x_{l}\\right)^{2}}} & \\frac{d \\sin{\\left(\\theta_{k} \\right)} + y_{k} - y_{l}}{\\sqrt{\\left(- d \\sin{\\left(\\theta_{k} \\right)} - y_{k} + y_{l}\\right)^{2} + \\left(- d \\cos{\\left(\\theta_{k} \\right)} - x_{k} + x_{l}\\right)^{2}}} & \\frac{- d \\left(- d \\sin{\\left(\\theta_{k} \\right)} - y_{k} + y_{l}\\right) \\cos{\\left(\\theta_{k} \\right)} + d \\left(- d \\cos{\\left(\\theta_{k} \\right)} - x_{k} + x_{l}\\right) \\sin{\\left(\\theta_{k} \\right)}}{\\sqrt{\\left(- d \\sin{\\left(\\theta_{k} \\right)} - y_{k} + y_{l}\\right)^{2} + \\left(- d \\cos{\\left(\\theta_{k} \\right)} - x_{k} + x_{l}\\right)^{2}}}\\\\- \\frac{d \\sin{\\left(\\theta_{k} \\right)} + y_{k} - y_{l}}{\\left(- d \\sin{\\left(\\theta_{k} \\right)} - y_{k} + y_{l}\\right)^{2} + \\left(- d \\cos{\\left(\\theta_{k} \\right)} - x_{k} + x_{l}\\right)^{2}} & - \\frac{- d \\cos{\\left(\\theta_{k} \\right)} - x_{k} + x_{l}}{\\left(- d \\sin{\\left(\\theta_{k} \\right)} - y_{k} + y_{l}\\right)^{2} + \\left(- d \\cos{\\left(\\theta_{k} \\right)} - x_{k} + x_{l}\\right)^{2}} & \\frac{d \\left(d \\sin{\\left(\\theta_{k} \\right)} + y_{k} - y_{l}\\right) \\sin{\\left(\\theta_{k} \\right)}}{\\left(- d \\sin{\\left(\\theta_{k} \\right)} - y_{k} + y_{l}\\right)^{2} + \\left(- d \\cos{\\left(\\theta_{k} \\right)} - x_{k} + x_{l}\\right)^{2}} - \\frac{d \\left(- d \\cos{\\left(\\theta_{k} \\right)} - x_{k} + x_{l}\\right) \\cos{\\left(\\theta_{k} \\right)}}{\\left(- d \\sin{\\left(\\theta_{k} \\right)} - y_{k} + y_{l}\\right)^{2} + \\left(- d \\cos{\\left(\\theta_{k} \\right)} - x_{k} + x_{l}\\right)^{2}} - 1\\end{matrix}\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EKF Estimatior\n",
    "# class EKF:\n",
    "#     def __init__(self, x0_hat, P0_hat, Q, R, T):\n",
    "#         self.x_hat = x0_hat\n",
    "#         self.P_hat = P0_hat\n",
    "#         self.x_check = None\n",
    "#         self.P_check = None\n",
    "#         self.Q = Q\n",
    "#         self.R = R\n",
    "#         self.T = T\n",
    "#         self.x_true = None\n",
    "\n",
    "#     def predict(self, u, using_x_true=False):\n",
    "#         if using_x_true:\n",
    "#             if self.x_true is None:\n",
    "#                 raise ValueError(\"x_true is not given\")\n",
    "#             else:\n",
    "#                 x_op = self.x_true\n",
    "#         else:\n",
    "#             x_op = self.x_hat\n",
    "\n",
    "#         # compute Jacobian h to x and w\n",
    "\n",
    "#         # compute x_check and P_check\n",
    "\n",
    "#     def correct(self, y):\n",
    "#         pass\n",
    "\n",
    "#     def get_result(self):\n",
    "#         return self.x_hat, self.P_hat\n",
    "\n",
    "#     def given_x_true(self, x_true):\n",
    "#         self.x_true = x_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# l = sp.io.loadmat(\"dataset2.mat\")[\"l\"]\n",
    "# animation = Animation(l)\n",
    "\n",
    "# mean = [1, 1]\n",
    "# cov = [[2, 1], [1, 2]]\n",
    "\n",
    "# timer = QtCore.QTimer()\n",
    "# timer.timeout.connect(\n",
    "#     lambda: animation.update(mean, cov, true_position=[mean[0] + 1, mean[1] + 1])\n",
    "# )\n",
    "# timer.start(1000)\n",
    "# pg.exec()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
